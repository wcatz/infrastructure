# Prometheus Helm Chart Values
# These values configure the Prometheus monitoring stack

server:
  enabled: true
  persistentVolume:
    enabled: true
    size: 8Gi
  retention: "15d"
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi

alertmanager:
  enabled: true
  persistentVolume:
    enabled: true
    size: 2Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

  # Alertmanager configuration
  config:
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
        - match:
            severity: critical
          receiver: 'critical'
          continue: true
        - match:
            severity: warning
          receiver: 'warning'

    receivers:
      - name: 'default'
        # Configure your default notification channel
        # webhook_configs:
        #   - url: 'http://webhook-receiver/alerts'

      - name: 'critical'
        # Configure critical alerts notification
        # email_configs:
        #   - to: 'alerts@example.com'
        #     from: 'prometheus@example.com'
        # slack_configs:
        #   - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        #     channel: '#alerts-critical'

      - name: 'warning'
        # Configure warning alerts notification
        # slack_configs:
        #   - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        #     channel: '#alerts-warning'

serverFiles:
  alerting_rules.yml:
    groups:
      - name: infrastructure
        interval: 30s
        rules:
          # Node/Pod availability alerts
          - alert: NodeDown
            expr: up{job="kubernetes-nodes"} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Node {{ $labels.instance }} is down"
              description: "Node {{ $labels.instance }} has been down for more than 5 minutes"

          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0.1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently ({{ $value }} restarts/sec in last 15 minutes)"

          # Resource alerts
          - alert: HighCPUUsage
            expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage on {{ $labels.instance }}"
              description: "CPU usage is above 80% for more than 10 minutes"

          - alert: HighMemoryUsage
            expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage on {{ $labels.instance }}"
              description: "Memory usage is above 90%"

          - alert: DiskSpaceLow
            expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Disk space low on {{ $labels.instance }}"
              description: "Disk usage is above 85% on {{ $labels.mountpoint }}"

          # Cloudflared tunnel alerts
          - alert: CloudflaredTunnelDown
            expr: up{job="cloudflared"} == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Cloudflared tunnel is down"
              description: "Cloudflared tunnel has been down for more than 2 minutes"

          - alert: CloudflaredHighErrorRate
            expr: rate(cloudflared_tunnel_response_errors_total[5m]) > 10
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High error rate on Cloudflared tunnel"
              description: "Cloudflared tunnel has high error rate for 5 minutes"

          # Velero backup alerts
          - alert: VeleroBackupFailed
            expr: velero_backup_failure_total > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Velero backup failed"
              description: "Backup {{ $labels.schedule }} has failed"

          - alert: VeleroBackupTooOld
            expr: time() - velero_backup_last_successful_timestamp{schedule!=""} > 86400
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Velero backup is too old"
              description: "Last successful backup for schedule {{ $labels.schedule }} was more than 24 hours ago"

          # Kubernetes alerts
          - alert: KubernetesPersistentVolumeFull
            expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Kubernetes PersistentVolume is almost full"
              description: "PersistentVolume {{ $labels.persistentvolumeclaim }} is {{ $value }}% full"

          - alert: KubernetesDeploymentReplicasMismatch
            expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Kubernetes Deployment replicas mismatch"
              description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $value }} replicas available, expected {{ $labels.spec_replicas }}"

nodeExporter:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

pushgateway:
  enabled: false

kubeStateMetrics:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi
